# üìÇ Clasificaci√≥n de Im√°genes con Deep Learning

## üìå Descripci√≥n del Proyecto
Este proyecto tiene como objetivo desarrollar y evaluar diferentes arquitecturas de **redes neuronales convolucionales (CNNs)** para la **clasificaci√≥n de im√°genes de flores**.  
Se trabaj√≥ con un dataset balanceado que fue dividido en **conjuntos de entrenamiento y validaci√≥n**, con el fin de comparar el rendimiento de tres modelos populares de deep learning.

## üóÇÔ∏è Dataset
Se utiliz√≥ el **Flower Photos Dataset**, disponible p√∫blicamente en TensorFlow. Este dataset contiene im√°genes de 5 categor√≠as de flores:  
![Ejemplo del dataset](https://storage.googleapis.com/tfds-data/visualization/fig/oxford_flowers102-2.1.1.png)
- üå∏ Daisies  
- üåº Dandelions  
- üåπ Roses  
- üåª Sunflowers  
- üå∑ Tulips  

- **Fuente oficial**: [Flower Photos Dataset](https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz)  
- **Tama√±o aproximado**: 3,670 im√°genes  
- **Divisi√≥n**: 80% entrenamiento y 20% validaci√≥n  
- **Preprocesamiento**: redimensionamiento, normalizaci√≥n y data augmentation para mejorar la generalizaci√≥n.  

## üß† Modelos Evaluados
- **ResNet50**: Red profunda con conexiones residuales que permiten un mejor flujo de gradientes.  
- **MobileNetV2**: Arquitectura ligera optimizada para dispositivos m√≥viles y entornos con recursos limitados.  
- **EfficientNetB0**: Modelo que escala de forma compuesta (profundidad, anchura y resoluci√≥n) para lograr eficiencia y precisi√≥n.  

## ‚öôÔ∏è Metodolog√≠a
1. Preprocesamiento de im√°genes (redimensionamiento y normalizaci√≥n).  
2. Transfer learning con pesos preentrenados en ImageNet.  
3. Fine-tuning de las capas superiores.  
4. Evaluaci√≥n con m√©tricas de clasificaci√≥n: **Accuracy, Precision (macro), Recall (macro) y F1-score (macro)**.  

## üìä Resultados Comparativos

| Modelo        | Accuracy | Precision (macro) | Recall (macro) | F1 (macro) |
|---------------|----------|-------------------|----------------|------------|
| ResNet50      | 0.8591   | 0.8610            | 0.8620         | 0.8585     |
| MobileNetV2   | 0.5841   | 0.5974            | 0.5872         | 0.5836     |
| **EfficientNetB0** | **0.9015** | **0.9017**       | **0.9026**      | **0.9016** |

## üîé An√°lisis
- **EfficientNetB0** obtuvo el mejor rendimiento en todas las m√©tricas, alcanzando un **90.15% de accuracy**. Su dise√±o eficiente y balanceado le permite extraer caracter√≠sticas de forma m√°s precisa sin aumentar demasiado el costo computacional.  
- **ResNet50** mostr√≥ un desempe√±o s√≥lido (**85.91% accuracy**), gracias a sus conexiones residuales que ayudan a evitar el problema del gradiente desapareciente. Es un buen compromiso entre precisi√≥n y complejidad.  
- **MobileNetV2** fue el modelo con menor desempe√±o (**58.41% accuracy**). Aunque est√° dise√±ado para ser r√°pido y ligero en dispositivos m√≥viles, sacrifica capacidad de representaci√≥n, lo que afect√≥ sus resultados en este dataset.  

## ‚úÖ Conclusi√≥n
- El **mejor modelo para este dataset es EfficientNetB0**, ya que combina eficiencia y alta precisi√≥n.  
- **ResNet50** es una alternativa recomendable si se cuenta con m√°s recursos computacionales.  
- **MobileNetV2** es √∫til √∫nicamente en escenarios donde la prioridad es la **baja demanda de recursos**, sacrificando exactitud en la clasificaci√≥n.  

---
